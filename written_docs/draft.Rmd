---
title: Race-based disparities in allocation of academic disciplinary actions are associated
  with county-level rates of bias
author:
- address: ''
  affiliation: '1'
  corresponding: yes
  email: triddle@princeton.edu
  name: Travis Riddle
- affiliation: '1'
  name: Stacey Sinclair
affiliation:
- id: '1'
  institution: Princeton University
output:
  papaja::apa6_word: default
  papaja::apa6_pdf: default
bibliography: ref.bib
class: man
figsintext: yes
figurelist: no
footnotelist: no
keywords: keywords
lang: english
lineno: yes
author_note: |
  Enter author note here.
shorttitle: Discipline Disparities
tablelist: no
abstract: |
  Enter abstract here.
wordcount: X
---

```{r include = FALSE}
library("papaja")
knitr::opts_chunk$set(echo = FALSE, cache=TRUE, cache.lazy = FALSE, 
                      message=FALSE, warning=FALSE, results='hide')
```
# Introduction

# Methods
## Data Sources
### Disciplinary actions
```{r summary-data}
library(dplyr)
library(forcats)
library(haven)
library(tidyr)
library(ggplot2)
county_means <- read.csv('/Users/travis/Documents/gits/educational_disparities/output/county_means.csv', 
                         colClasses = 'character')
schools_dat <- read.csv('/Users/travis/Documents/gits/Data/crdc201314csv/CRDC2013_14_SCH.csv')
model.data <- read.csv('/Users/travis/Documents/gits/educational_disparities/output/full_model_data.csv')

model.data %>%
  filter(exclude==FALSE) %>%
  select(COMBOKEY, group, total_number) %>%
  distinct() %>%
  mutate(total_schools = n_distinct(COMBOKEY)) %>%
  group_by(group) %>%
  summarise(ns = sum(total_number),
            n_sch = n_distinct(COMBOKEY),
            total_schools = max(total_schools)) -> enrollment_totals

```
To assess rates of disciplinary action, we used data from the Civil Rights Data Collection (CRDC) conducted by the US Department of Education. The dataset we used comes from the 2013-2014 academic year and has data on "all public local and educational agencies and schools, including long-term secure juvenile justice facilities, charter schools, alternative schools, and schools serving students with disabilities." In total, the CRDC data represents `r dim(schools_dat)[1]` institutions enrolling approximately 50 million students, of which approximately 25 million are white and 7.8 million are Black[^1]. Previous work using these data have identified a number of districts whose data are in error, and have excluded juvenile justice facilities, as these institutions constitute dramatically different educational environments, where the meaning of disciplinary actions may be quite different [@losen2015we]. After these exclusions are applied, the final sample used for modeling consists of `r enrollment_totals$total_schools[1]` institutions, enrolling `r round(sum(enrollment_totals$ns)/1000000, 1)` million black or white students, of which `r  round(enrollment_totals$ns[2]/1000000)` million are white and `r  round(enrollment_totals$ns[1]/1000000)` million are black. From these data, we focus on the number of students by race (black and white) who received one of several types of disciplinary action. We report here rates of out-of-school suspension, in-school suspension, school-related arrests, law enforcement referrals, and total number of expulsions of any type.

[^1]: We note that there are a number of differences between the analyses we registered and those presented in the main text. Our general conclusions are largely the same for both sets of analyses. We opted to report the modified analyses for reasons of clarity and to remain congruent with previous research on the same topics. The registered analyses can be found, in full, in the appendix.

### Racial Bias
```{r iat-data}
df <- rbind(read_sav('/Users/travis/Documents/gits/Data/iat/Race IAT.public.2013.sav'),
            read_sav('/Users/travis/Documents/gits/Data/iat/Race IAT.public.2012.sav'),
            read_sav('/Users/travis/Documents/gits/Data/iat/Race IAT.public.2010.sav'))

df2 <- read_sav('/Users/travis/Documents/gits/Data/iat/Race IAT.public.2011.sav')
df3 <- read_sav('/Users/travis/Documents/gits/Data/iat/Race IAT.public.2009.sav')
df4 <- read_sav('/Users/travis/Documents/gits/Data/iat/Race IAT.public.2008.sav')
df5 <- read_sav('/Users/travis/Documents/gits/Data/iat/Race IAT.public.2007.sav')
df6 <- read_sav('/Users/travis/Documents/gits/Data/iat/Race IAT.public.2006.sav')
df7 <- read_sav('/Users/travis/Documents/gits/Data/iat/Race IAT.public.2005.sav')
df8 <- read_sav('/Users/travis/Documents/gits/Data/iat/Race IAT.public.2004.sav')
df9 <- read_sav('/Users/travis/Documents/gits/Data/iat/Race IAT.public.2002-2003.sav')
df10 <- read_sav('/Users/travis/Documents/gits/Data/iat/Race IAT.public.2014.sav')

"%ni%" <- Negate("%in%")

df %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblack_0to10) &
           !is.na(age)) %>%
  dplyr::select(CountyNo, STATE, D_biep.White_Good_all, 
         tblack_0to10, twhite_0to10, raceomb, age) %>%
  filter(raceomb==5 | raceomb==6) -> subdat

df2 %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblack_0to10) &
           !is.na(age)) %>%
  dplyr::select(CountyNo, STATE, D_biep.White_Good_all,  
         tblack_0to10, twhite_0to10, raceomb, age) %>%
  rbind(subdat) %>%
  filter(raceomb==5 | raceomb==6) -> subdat

df3 %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblack_0to10) &
           !is.na(age)) %>%
  dplyr::select(CountyNo, STATE, D_biep.White_Good_all, 
         tblack_0to10, twhite_0to10, raceomb, age) %>%
  rbind(subdat) %>%
  filter(raceomb==5 | raceomb==6) -> subdat

df4 %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblack_0to10) &
           !is.na(age)) %>%
  dplyr::select(CountyNo, STATE, D_biep.White_Good_all, 
         tblack_0to10, twhite_0to10, raceomb, age) %>%
  rbind(subdat) %>%
  filter(raceomb==5 | raceomb==6) -> subdat

df5 %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblack_0to10) &
           !is.na(age)) %>%
  dplyr::select(CountyNo, STATE, D_biep.White_Good_all, 
         tblack_0to10, twhite_0to10, raceomb, age) %>%
  rbind(subdat) %>%
  filter(raceomb==5 | raceomb==6) -> subdat

df6 %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblack_0to10) &
           !is.na(age)) %>%
  dplyr::select(CountyNo, STATE, D_biep.White_Good_all, 
         tblack_0to10, twhite_0to10, raceomb, age) %>%
  rbind(subdat) %>%
  filter(raceomb==5 | raceomb==6) -> subdat

df7 %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblacks_0to10) &
           !is.na(age)) %>%
  mutate(tblack_0to10=tblacks_0to10,
         twhite_0to10=twhites_0to10) %>%
  mutate(raceomb = ethnic) %>%
  dplyr::select(CountyNo, STATE, D_biep.White_Good_all, 
         tblack_0to10, twhite_0to10, raceomb, age) %>%
  rbind(subdat) %>%
  filter(raceomb==5 | raceomb==6) -> subdat

df8 %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblacks_0to10) &
           !is.na(age)) %>%
  mutate(tblack_0to10=tblacks_0to10,
         twhite_0to10=twhites_0to10) %>%
  mutate(raceomb = ethnic) %>%
  dplyr::select(CountyNo, STATE, D_biep.White_Good_all, 
         tblack_0to10, twhite_0to10, raceomb, age) %>%
  rbind(subdat) %>%
  filter(raceomb==5 | raceomb==6) -> subdat

df9 %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblacks_0to10) &
           !is.na(age)) %>%
  mutate(raceomb = ethnic) %>%
  mutate(tblack_0to10=tblacks_0to10,
         twhite_0to10=twhites_0to10) %>%
  dplyr::select(CountyNo, STATE, D_biep.White_Good_all, 
         tblack_0to10, twhite_0to10, raceomb, age) %>%
  rbind(subdat) %>%
  filter(raceomb==5 | raceomb==6) -> subdat

df10 %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblack_0to10) &
           !is.na(age)) %>%
  dplyr::select(CountyNo, STATE, D_biep.White_Good_all, 
         tblack_0to10, twhite_0to10, raceomb, age) %>%
  rbind(subdat) %>%
  filter(raceomb==5 | raceomb==6) -> subdat

subdat %>%
  mutate(explicit_bias=tblack_0to10) %>%
  #filter(!is.na(twhite_0to10)) %>%
  #mutate(explicit_bias = twhite_0to10 - tblack_0to10) %>%
  mutate(age_bin = cut(age, breaks=c(14, 24, 34, 54, 75, 120))) %>%
  mutate(race = fct_recode(as.character(raceomb), 
                           'Black'='5', 'White'='6')) %>%
  filter(!is.na(age_bin)) %>%
  filter(race=='White') %>%
  filter(STATE %ni% 
           c('AA', 'AE', 'AP', 'AS', 'FM', 'GU', 'MH', 'MP', 'PR', 'VI')) %>%
  mutate(county_id = paste(STATE, CountyNo, sep='-')) -> individual_data

```

We used measurements of implicit and explicit bias available from data collected through Project Implicit [@xu2014psychology]. For a full description of the implicit and explicit bias measures available in these data, refer to @xu2014psychology and @leitner2016blacks. From this data, we used only respondents who had geographic information that would allow us to place them in a United States county, identified as White, and visited the site before 2015. This consisted of approximately 1.1 million total respondents from `r dim(county_means)[1]` counties.

Because Project Implicit is a nonrandom sample, we used multilevel regression and post-stratification to obtain accurate geographical population-based estimates of implicit and explicit bias. Multilevel regression and post-stratification corrects for biased sampling and regularizes extreme observations with little data to support them (e.g. a county with only a handful of respondents with especially high or low scores) [@park2004bayesian; @gelman1997poststratification]. Following past work [@leitner2016blacks], we identified age as one dimension along which IAT respondents differed from the general population in ways that could bias our conclusions [@gonsalkorale2009aging]. Our post-stratification weighting scheme is as follows: We first grouped respondents into five age group categories (15-24, 25-34, 35-54, 55-75, and 75+). We next fit multilevel models estimating bias (implicit and explicit biases seperately) as a function of our state-level covariates (the "fixed" effects: proportion of population that is white; proportion of the population that is black, the ratio of black to white people in the population, the percentage of college graduates, the unemployment rate, the median household income, and the poverty rate), and allowed the estimates to vary by age bin, county, and state (the "random" effects). Next, we determined the population of whites in each county in these age groups using the American Community Survey's 5-year estimates ending in 2014. Finally, we used our estimated models to predict the expected response for each age bin, in each county. Our final county-level estimates are the average of the values predicted for the 5 age bins, weighted by the population size of that bin in that county. As a result of this procedure, we can be confident that our county-level estimates should more closely approximate what our estimates would look like if the Project Implicit data were truly representative along the age dimension in all counties.

### Covariates
All county-level demographic information for use as covariates and state-level demographic information for use in post-stratification were taken from the US Census Bureau. For both county-level and state-level demographics, we use 5-year estimates for the period ending in 2014 from the American Community Survey, which surveys around 295k households per month. We additionally took an estimate of violent crime from the FBI Uniform Crime Reporting program, as made available through the National Archive of Criminal Justice Data.



## Measures

For both the post-stratification procedure (described below) and the actual statistical models used for inference, we used the same set of covariates. These covariates were at the state-level for post-stratification and were at the county-level for the statistical models used for final estimation and inference. Specifically, our population based covariates were the total population count, the proportion of the population that is black, the proportion of the population that is white and the ratio of black-to-white persons. We also used socioeconomic covariates. We used the percent of individuals aged 16 or over who were in the labor force but unemployed, the median household income, and the percentage of all families whose income is below the poverty line.



## Data analysis
Data analysis proceded in two steps. 

After obtaining these estimates, we use them as predictors in bayesian multilevel logistic regressions. Formally, the likelihood for a given observation is written as a binomial function:

$$
{n\choose y}\pi^y(1-\pi)^{n-y}
$$

Where $y$ is the observed count of incidents (e.g. number of black or white students suspended), $n$ is the number of at-risk students (e.g. total number of black or white students), and $\pi = g^{-1}(\eta)$ is the probability of the incident ocurring. For this analysis, the linear predictor takes the form of a multilevel model with a set of effects that vary over county:

$$
\eta = \alpha + X\beta + \gamma_{county}
$$

Where $\alpha$ is an intercept that is constant across observations, $\beta$ represents a set of effects that are also constant across observations (i.e. fixed effects), and $\gamma_{county}$ represents intercepts and effects of ethnicity that vary across the counties (i.e. random efffects).

In addition to the covariates described above, we also include effects of race, implicit bias, explicit bias, and the two-way interactions between implicit bias and race and explicit bias and race. We fit separate models for each of the outcomes.

Because of the computational demands of fitting such a high-dimensional model to such a large dataset (the full model for each metric would consist of over 6k parameters to approximately 170k observations), we used a consensus monte carlo algorithm to obtain approximate posterior distributions for the parameters of interest [@scott2016bayes]. The approximate posteriors derived from this algorithm have been shown to be nearly indistinguishable from the true posterior, a result we verified using a small subset of our own data.

All numerical predictor variables were standardized at the appropriate level (county, state) before model estimation to help with estimation efficiency and interpretability. We set priors for the intercept and coefficients in the bayesian models to be weakly informative normal distributions centered on zero with a standard deviation of five. All other parameters were left to default values. Data analysis was done in R [@rcitation] version 3.3.2 running under OS X 10.11.6. Post-stratification was done with lme4, version 1.1.14 [@bates2015fitting]. Final model fitting was done on the university cluster running Springdale Linux, release 6.9 using rstanarm, version 2.17.2 [@rstanarm2016]. We used the implementation of the consensus monte carlo algorithm found in parallelMCMCcombine, version 1.0 [@miroshnikov2014parallel]. Figures were made with ggplot2, version 2.2.1 [@wickham2009ggplot2], with data manipulation done using dplyr version 0.7.2 [@wickham2017dplyr] and tidyr, version 0.7.1 [@wickham2017tidyr]. A full report of session information can be found on the OSF page (....)


# Results
## Project Implicit Estimates
```{r exp-diff}
individual_data %>%
  mutate(explicit_bias_diff = twhite_0to10-tblack_0to10) -> individual_data
```
We first report the results of estimating the implicit and explicit biases in from Project Implicit data. Overall, the individuals in project implicit show a pro-white bias in both implicit (*mean* = `r round(mean(individual_data$D_biep.White_Good_all), 2)`, *sd* = `r round(sd(individual_data$D_biep.White_Good_all), 2)`), and explicit measures (*mean* = `r round(mean(individual_data$explicit_bias_diff, na.rm=T), 2)` *sd* = `r round(sd(individual_data$explicit_bias_diff, na.rm=T), 2)`). When aggregated at the county level and adjusted with poststratification, the summary statistics across counties are similar in terms of their location, but as expected, the variability is much diminished ($mean_{implicit}$ = `r round(mean(as.numeric(county_means$weighted_bias), na.rm=T), 2)`, $sd_{implicit}$ = `r round(sd(as.numeric(county_means$weighted_bias), na.rm=T), 2)`; $mean_{explicit}$ = `r round(mean(as.numeric(county_means$weighted_explicit_diff), na.rm=T), 2)`, $sd_{explicit}$ = `r round(sd(as.numeric(county_means$weighted_explicit_diff), na.rm=T), 2)`, where on both scales 0 = no bias, and positive numbers indicate a pro-white bias).

## Disciplinary action frequency

```{r disc-count, results='asis'}
model.data %>% 
  filter(exclude==FALSE) %>%
  group_by(group, metric) %>% 
  summarise(students = sum(number)) %>%
  mutate(metric = fct_recode(metric, 
                             'expulsions' = 'expulsion_combined',
                             'school arrests' = 'in_school_arrest',
                             'in-school suspension' = 'inschool_susp',
                             'law enforcement referral' = 'law_enforcement',
                             'out-of-school suspension' = 'oos_susp')) -> counts_table

apa_table(counts_table, caption = 'Count of students by race receiving each type of disciplinary action')
```

Table \@ref(tab:disc-count) shows the number of students of each race who were reported having received each of the actions under consideration. The counts range from a low of just `r counts_table$students[7]` white students arrested to a high of `r counts_table$students[5]` black students receiving an out-of-school suspension. Considering the vast differences in the overall number of black and white students, this simple count already illustrates that black students are disciplined at rates far higher than their white counterparts.

## Associations across county
Figure \@ref(fig:overall-associations) shows the estimate of primary interest for each of the models. The estimates displayed are the coefficients for the interaction between race and each of the two bias measurements. Given that African Americans are the baseline group, negative values for this coefficient indicate that as the bias in a county increases, the gap between the probability of a black student being disciplined and the probability of a white student being disciplined grows.

```{r overall-associations, fig.cap="Association between each metric and county-level estimates of explicit and implicit bias. Negative values indicate that the rate of increase (or decrease) for blacks is faster (or slower) than for whites. Point is the mean of the posterior and error bars represent 95% bayesian uncertainty intervals."}
#the p_neg for oos_susp & implicit bias is 100%, so when reporting the number in-text, i just replace it with 1 to prevent it from being rendered as NA in the document.
base_path <- '/Users/travis/Documents/gits/educational_disparities/cluster/output/mw_uclaexcl_diff_extracovs/'
plot.dat <- data.frame(group = NA, weighted_bias = NA, est = NA, lower = NA, upper=NA, metric = NA)
plot.dat2 <- data.frame(weighted_bias = NA, est = NA, lower=NA, upper=NA, metric=NA)
plot.dat3 <- data.frame(est=NA, lower=NA, upper=NA, p_neg=NA, metric=NA)

# weighted bias w/exclusions & explicit difference
metrics <- list.files(base_path)
#metrics <- c('expulsion_combined', 'inschool_susp', 'oos_susp')
for (i in metrics){
  pth <- paste(base_path, i, '/', sep='')
  
  files <- list.files(pth)
  j <- 1
  posterior_combo <- array(0, dim=c(16,4000,length(files)))
  raw_rate <- data.frame(county_id=NA, nschools=NA, weighted_bias=NA, group=NA, nincidents=NA, nstudents=NA, rate=NA)
  for (k in files){
    #print(i)
    load(paste(pth,k,sep=''))
    df <- as.matrix(m)
    m$data %>% 
      select(county_id, COMBOKEY) %>% 
      distinct() %>% 
      group_by(county_id) %>% 
      summarise(nschools=n()) -> n_schools
    m$data %>%
      group_by(county_id, group) %>%
      summarise(nincidents=sum(number), nstudents=sum(total_number)) %>%
      mutate(rate=nincidents/nstudents) -> rate
    n_schools %>%
      left_join(m$data[, c('county_id', 'weighted_bias')]) %>%
      distinct() %>%
      left_join(rate) %>%
      rbind(raw_rate) %>%
      filter(!is.na(county_id)) -> raw_rate
    posterior_combo[,,j] <- t(df[,c(1:16)])
    j <- j+1
  }
  p_cons <- parallelMCMCcombine::consensusMCcov(posterior_combo, shuff = T)
  
  for (p in 1:16){
    m$stanfit@sim$samples[[1]][[p]] <- p_cons[p,1:1000]
  }
  for (p in 1:16){
    m$stanfit@sim$samples[[2]][[p]] <- p_cons[p,1001:2000]
  }
  for (p in 1:16){
    m$stanfit@sim$samples[[3]][[p]] <- p_cons[p,2001:3000]
  }
  for (p in 1:16){
    m$stanfit@sim$samples[[4]][[p]] <- p_cons[p,3001:4000]
  }
  
  data.frame(est=mean(p_cons[15,]),
             lower=quantile(p_cons[15,], .025),
             upper=quantile(p_cons[15,], .975),
             p_neg = prop.table(table(p_cons[15,]<0))[2],
             metric=i) %>%
    rbind(plot.dat3) %>%
    filter(!is.na(est)) %>%
    mutate(metric=reorder(metric, est)) -> plot.dat3
}

plot.dat3$metric <- fct_recode(plot.dat3$metric, 
                               'Out-of-School Suspension' = 'oos_susp',
                               'In-School Suspension' = 'inschool_susp',
                               'School-Related Arrest' = 'in_school_arrest',
                               'Law Enf. Referral' = 'law_enforcement',
                               'Expulsion' = 'expulsion_combined')
plot.dat3_all <-plot.dat3
plot.dat3_all$bias <- 'Implicit'

#weighted warmth w/exclusions & explicit difference
plot.dat <- data.frame(group = NA, weighted_explicit_diff = NA, est = NA, lower = NA, upper=NA, metric = NA)
plot.dat2 <- data.frame(weighted_explicit_diff = NA, est = NA, lower=NA, upper=NA, metric=NA)
plot.dat3 <- data.frame(est=NA, lower=NA, upper=NA, p_neg = NA, metric=NA)

for(i in metrics){
  pth <- paste(base_path, i, '/', sep='')
  
  files <- list.files(pth)
  j <- 1
  posterior_combo <- array(0, dim=c(16,4000,length(files)))
  raw_rate_warmth <- data.frame(county_id=NA, nschools=NA, weighted_explicit_diff=NA, group=NA, nincidents=NA, nstudents=NA, rate=NA)
  for (k in files){
    #print(i)
    load(paste(pth,k,sep=''))
    df <- as.matrix(m)
    m$data %>% 
      select(county_id, COMBOKEY) %>% 
      distinct() %>% 
      group_by(county_id) %>% 
      summarise(nschools=n()) -> n_schools
    m$data %>%
      group_by(county_id, group) %>%
      summarise(nincidents=sum(number), nstudents=sum(total_number)) %>%
      mutate(rate=nincidents/nstudents) -> rate
    n_schools %>%
      left_join(m$data[, c('county_id', 'weighted_explicit_diff')]) %>%
      distinct() %>%
      left_join(rate) %>%
      rbind(raw_rate_warmth) %>%
      filter(!is.na(county_id)) -> raw_rate_warmth
    posterior_combo[,,j] <- t(df[,c(1:16)])
    j <- j+1
  }
  p_cons <- parallelMCMCcombine::consensusMCcov(posterior_combo, shuff = T)
  
  for (p in 1:16){
    m$stanfit@sim$samples[[1]][[p]] <- p_cons[p,1:1000]
  }
  for (p in 1:16){
    m$stanfit@sim$samples[[2]][[p]] <- p_cons[p,1001:2000]
  }
  for (p in 1:16){
    m$stanfit@sim$samples[[3]][[p]] <- p_cons[p,2001:3000]
  }
  for (p in 1:16){
    m$stanfit@sim$samples[[4]][[p]] <- p_cons[p,3001:4000]
  }
  
  data.frame(est=mean(p_cons[16,]),
             lower=quantile(p_cons[16,], .025),
             upper=quantile(p_cons[16,], .975),
             p_neg = prop.table(table(p_cons[16,]<0))[2],
             metric=i) %>%
    rbind(plot.dat3) %>%
    filter(!is.na(est)) %>%
    mutate(metric=reorder(metric, est)) -> plot.dat3
}

plot.dat3$bias <- 'Explicit'
plot.dat3$metric <- fct_recode(plot.dat3$metric, 
                               'Out-of-School Suspension' = 'oos_susp',
                               'In-School Suspension' = 'inschool_susp',
                               'School-Related Arrest' = 'in_school_arrest',
                               'Law Enf. Referral' = 'law_enforcement',
                               'Expulsion' = 'expulsion_combined')
plot.dat3_all <- rbind(plot.dat3_all, plot.dat3)
ggplot(plot.dat3_all, aes(x=metric, y=est, group=bias, color=bias, shape=bias)) +
  geom_point(position=position_dodge(width=.5), size=2) +
  geom_errorbar(aes(ymin=lower, ymax=upper), 
                width=.5, position=position_dodge(width=.5)) +
  theme_classic() +
  coord_flip() +
  geom_hline(yintercept=0) +
  ylab('Black-White Difference in log-odds slope') +
  theme(axis.title.y = element_blank(),
        legend.title = element_blank())
```

Several patterns are apparent from this figure. First, with the exceptions of implicit bias and expulsions and law enforcement referrals, all estimates are directionally consistent with higher levels of bias leading to larger differences between groups. Second, these effects are especially consistent for the two types of suspensions. The largest effect estimated is between implicit bias and out-of-school suspensions. The difference in the slope of the association between implicit bias and the log of the odds for out-of-school suspensions between white and black students is estimated to be `r round(plot.dat3_all$est[1], 2)`, with 95% of the posterior distribution between `r round(plot.dat3_all$lower[1], 2)` and `r round(plot.dat3_all$upper[1], 2)` and a proportion `r afex::round_ps(1)` of the posterior distribution consistent with a negative effect. 

Although not nearly as large of a difference, we have similar certainty with respect to the association between out-of-school suspensions and explicit bias. The difference in the slope of the association between explicit bias and the log of the odds for out-of-school suspensions between white and black students is estimated to be `r round(plot.dat3_all$est[6], 2)`, with 95% of the posterior distribution between `r round(plot.dat3_all$lower[6], 2)` and `r round(plot.dat3_all$upper[6], 2)` and a proportion `r afex::round_ps(plot.dat3_all$p_neg[6])` of the posterior distribution consistent with a negative effect. 

The estimated associations for in-school suspensions are smaller still, but are generally consistent with effects of the same direction. For implicit bias, the relevant parameter is estimated at `r round(plot.dat3_all$est[3], 2)` [`r round(plot.dat3_all$lower[3], 2)`, `r round(plot.dat3_all$upper[3], 2)`] $p_{neg}$ = `r round(plot.dat3_all$p_neg[3], 2)`, and for explicit bias, the effect is slightly larger, and a positive effect is essentially not credible, given the data and model `r round(plot.dat3_all$est[8], 2)` [`r round(plot.dat3_all$lower[8], 2)`, `r round(plot.dat3_all$upper[8], 2)`] $p_{neg}$ `r afex::round_ps(plot.dat3_all$p_neg[8])`.

Other outcomes are estimated with less precision, or with patterns that are inconsistent between implicit and explicit bias. For instance, examining the associations for expulsions, the effect of explicit biases are generally in the expected direction (*est* = `r round(plot.dat3_all$est[10], 2)`, [`r round(plot.dat3_all$lower[10], 2)`, `r round(plot.dat3_all$upper[10], 2)`], $p_{neg}$ = `r afex::round_ps(plot.dat3_all$p_neg[10])`), but the effect for implicit bias is estimated to be close to zero, with a enough uncertainty (*est* = `r round(plot.dat3_all$est[5], 2)`, [`r round(plot.dat3_all$lower[5], 2)`, `r round(plot.dat3_all$upper[5], 2)`], $p_{neg}$ = `r afex::round_ps(plot.dat3_all$p_neg[5])`) to make it difficult to claim an effect of one direction or the other. The model indicates similar uncertainty with respect to school-related arrests and both estimates of bias ($est_{explicit}$ = `r round(plot.dat3_all$est[9], 2)`, [`r round(plot.dat3_all$lower[9], 2)`, `r round(plot.dat3_all$upper[9], 2)`], $p_{neg}$ = `r afex::round_ps(plot.dat3_all$p_neg[9])`; $est_{implicit}$ = `r round(plot.dat3_all$est[4], 2)`, [`r round(plot.dat3_all$lower[4], 2)`, `r round(plot.dat3_all$upper[4], 2)`], $p_{neg}$ = `r afex::round_ps(plot.dat3_all$p_neg[4])`).

```{r detail-fig-exp, fig.cap="Association between bias and expulsions. Top: Association between bias and the estimated probability of expulsion. Line is the mean of the posterior. Bands indicate 95% uncertainty intervals; Bottom: Association between bias and the relative risk ratio for black students to white students. Points represent counties, whose size are scaled to the number of schools in that county."}
library(gridExtra)
i <- 'expulsion_combined'
pth <- paste(base_path, i, '/', sep='')

files <- list.files(pth)
j <- 1
posterior_combo <- array(0, dim=c(14,4000,length(files)))
raw_rate <- data.frame(county_id=NA, nschools=NA, weighted_bias=NA, 
                       weighted_warmth=NA, group=NA, nincidents=NA, 
                       nstudents=NA, rate=NA)
for (k in files){
  #print(i)
  load(paste(pth,k,sep=''))
  df <- as.matrix(m)
  m$data %>% 
    select(county_id, COMBOKEY) %>% 
    distinct() %>% 
    group_by(county_id) %>% 
    summarise(nschools=n()) -> n_schools
  m$data %>%
    group_by(county_id, group) %>%
    summarise(nincidents=sum(number), nstudents=sum(total_number)) %>%
    mutate(rate=nincidents/nstudents) -> rate
  n_schools %>%
    left_join(m$data[, c('county_id', 'weighted_bias', 'weighted_warmth')]) %>%
    distinct() %>%
    left_join(rate) %>%
    rbind(raw_rate) %>%
    filter(!is.na(county_id)) -> raw_rate
  posterior_combo[,,j] <- t(df[,c(1:14)])
  j <- j+1
}
p_cons <- parallelMCMCcombine::consensusMCcov(posterior_combo, shuff = T)

for (p in 1:14){
  m$stanfit@sim$samples[[1]][[p]] <- p_cons[p,1:1000]
}
for (p in 1:14){
  m$stanfit@sim$samples[[2]][[p]] <- p_cons[p,1001:2000]
}
for (p in 1:14){
  m$stanfit@sim$samples[[3]][[p]] <- p_cons[p,2001:3000]
}
for (p in 1:14){
  m$stanfit@sim$samples[[4]][[p]] <- p_cons[p,3001:4000]
}

newdat <- expand.grid(group = rownames(table(m$data$group)),
                      total_pop=0,
                      unemp_rate=0,
                      med_income=0,
                      poverty_rate=0,
                      col_grads=0,
                      white_prop=0,
                      black_prop=0,
                      b.w.ratio=0,
                      weighted_bias = seq(-2.5,2.5,.25),
                      weighted_warmth = 0,
                      number=0,
                      total_number=1)
y_hat <- rstanarm::posterior_linpred(m, newdata = newdat, re.form=~0, transform=T)

cbind(newdat, t(y_hat)) %>% 
  mutate(index=row_number()) %>%
  gather(sample, value, `1`:`4000`) -> posterior_distribution


posterior_distribution %>%
  select(group, weighted_bias, sample, value, index) %>%
  group_by(group, weighted_bias) %>%
  summarise(est = mean(value),
            lower = quantile(value, .025),
            upper = quantile(value, .975)) %>%
  ungroup() %>%
  mutate(bias = 'Implicit') -> plot.dat

newdat <- expand.grid(group = rownames(table(m$data$group)),
                      total_pop=0,
                      unemp_rate=0,
                      med_income=0,
                      poverty_rate=0,
                      col_grads=0,
                      white_prop=0,
                      black_prop=0,
                      b.w.ratio=0,
                      weighted_bias = 0,
                      weighted_warmth = seq(-2.5,2.5,.25),
                      number=0,
                      total_number=1)
y_hat <- rstanarm::posterior_linpred(m, newdata = newdat, re.form=~0, transform=T)

cbind(newdat, t(y_hat)) %>% 
  mutate(index=row_number()) %>%
  gather(sample, value, `1`:`4000`) -> posterior_distribution


posterior_distribution %>%
  select(group, weighted_warmth, sample, value, index) %>%
  mutate(weighted_bias = weighted_warmth) %>%
  group_by(group, weighted_bias) %>%
  summarise(est = mean(value),
            lower = quantile(value, .025),
            upper = quantile(value, .975)) %>%
  ungroup() %>%
  mutate(bias = 'Explicit') %>%
  rbind(plot.dat) -> plot.dat


ggplot(plot.dat, aes(x=weighted_bias, y=est, group=group, linetype=group)) +
  geom_line(aes(color=group)) +
  geom_ribbon(aes(ymin=lower, ymax=upper), alpha=.15) +
  theme_classic() +
  ylab('Probability \n of Expulsion') +
  xlab('Standardized Bias') + 
  facet_wrap(~bias, ncol=2) +
  xlim(-3.5, 3.5) +
  theme(legend.title = element_blank(),
        axis.title.x = element_blank()) -> p1

posterior_distribution %>%
  select(group, weighted_warmth, sample, value) %>%
  spread(group, value) %>%
  mutate(ratio = black/white) %>%
  mutate(weighted_bias = weighted_warmth) %>%
  group_by(weighted_bias) %>%
  summarise(est = mean(ratio),
            lower = quantile(ratio, .025),
            upper = quantile(ratio, .975)) %>%
  ungroup() %>%
  mutate(bias = 'Explicit') -> plot.dat

newdat <- expand.grid(group = rownames(table(m$data$group)),
                      total_pop=0,
                      unemp_rate=0,
                      med_income=0,
                      poverty_rate=0,
                      col_grads=0,
                      white_prop=0,
                      black_prop=0,
                      b.w.ratio=0,
                      weighted_bias = seq(-2.5,2.5,.25),
                      weighted_warmth = 0,
                      number=0,
                      total_number=1)
y_hat <- rstanarm::posterior_linpred(m, newdata = newdat, re.form=~0, transform=T)

cbind(newdat, t(y_hat)) %>% 
  mutate(index=row_number()) %>%
  gather(sample, value, `1`:`4000`) -> posterior_distribution

posterior_distribution %>%
  select(group, weighted_bias, sample, value) %>%
  spread(group, value) %>%
  mutate(ratio = black/white) %>%
  group_by(weighted_bias) %>%
  summarise(est = mean(ratio),
            lower = quantile(ratio, .025),
            upper = quantile(ratio, .975)) %>%
  ungroup() %>%
  mutate(bias = 'Implicit') %>%
  rbind(plot.dat) -> plot.dat

raw_rate %>%
  mutate(Implicit = weighted_bias,
         Explicit = weighted_warmth) %>%
  select(-weighted_bias, -weighted_warmth) %>%
  gather(bias, value, Implicit:Explicit) %>%
  select(county_id, nschools, bias, group, rate, value) %>%
  spread(group, rate) %>%
  mutate(odds_r = black/white) -> raw_or
  

ggplot(plot.dat, aes(x=weighted_bias, y=est)) +
  geom_point(data=raw_or, aes(x=value, y=odds_r, size=nschools), alpha=.075) +
  geom_line() +
  geom_ribbon(aes(ymin=lower, ymax=upper), alpha=.25) +
  theme_classic() +
  #scale_color_manual(values=c('grey', 'darkorange'), guide=F) + 
  scale_alpha_manual(values=c(.2, 1), guide=F) +
  ylim(0,9) +
  xlim(-3.5, 3.5) + 
  xlab('Standardized Bias') +
  ylab('Relative \n Risk Ratio') +
  geom_hline(yintercept=1) +
  facet_wrap(~bias) -> p2

p1$data %>% filter(weighted_bias %in% c(0, 1)) -> rates
p2$data %>% filter(weighted_bias %in% c(0, 1)) -> risks

grid.arrange(p1, p2)
```

To better illustrate the nature of these relationships, figure \@ref(fig:detail-fig-exp) shows the estimated probabilities of expulsion for black and white students as a function of bias, along with the relative risk ratio for black students. The relative risk ratio is the ratio of the probability that a black student will be expelled to the probability that a white student will get expelled. Values over 1 reflect higher levels of punishment for black students. As previously indicated in table \@ref(tab:disc-count), the top part of this figure makes plain the higher probability of expulsion for black children. In a county at the mean of the distribution of bias, approximately `r round(rates$est*100, 2)[1]`% of black students are expected to be expelled [`r round(rates$lower*100, 2)[1]`, `r round(rates$upper*100, 2)[1]`]. The corresponding rate for white students is much lower, with about `r round(rates$est*100, 2)[3]`% expected to be expelled [`r round(rates$lower*100, 2)[3]`, `r round(rates$upper*100, 2)[3]`]. Moving to a county one standard deviation above the mean of explicit bias has the effect of increasing the estimated percentage of black students expected to be expelled to `r round(rates$est*100, 2)[2]`% [`r round(rates$lower*100, 2)[2]`, `r round(rates$upper*100, 2)[2]`], while the percentage of white students expected to be expelled would decline to `r round(rates$est*100, 2)[4]`% [`r round(rates$lower*100, 2)[4]`, `r round(rates$upper*100, 2)[4]`]. The same movement for implicit bias would slightly increase the expected expulsions for black students ( `r round(rates$est*100, 2)[6]`% [`r round(rates$lower*100, 2)[6]`, `r round(rates$upper*100, 2)[6]`), and increase the expected expulsions for white students a very small amount more to (`r round(rates$est*100, 2)[8]`% [`r round(rates$lower*100, 2)[8]`, `r round(rates$upper*100, 2)[8]`). In real terms, in a county at the mean of the distributions of bias, for every white student expelled, we should expect `r round(risks$est[1], 2)` [`r round(risks$lower[1], 2)`, `r round(risks$est[1], 2)`] black students to be expelled. If we move to a county one standard deviation above the mean of explicit bias, the ratio of black to white students expelled increases to `r round(risks$est[4], 2)` [`r round(risks$lower[4], 2)`, `r round(risks$est[4], 2)`], while the same movement for implicit bias slightly decreases the ratio to `r round(risks$est[2], 2)` [`r round(risks$lower[2], 2)`, `r round(risks$est[2], 2)`].

```{r detail-fig-susp, fig.cap="Association between bias and out-of-school suspensions Top: Association between bias and the estimated probability of suspension Line is the mean of the posterior. Bands indicate 95% uncertainty intervals; Bottom: Association between bias and the relative risk ratio for black students to white students. Points represent counties, whose size are scaled to the number of schools in that county."}
i <- 'oos_susp'
pth <- paste(base_path, i, '/', sep='')

files <- list.files(pth)
j <- 1
posterior_combo <- array(0, dim=c(14,4000,length(files)))
raw_rate <- data.frame(county_id=NA, nschools=NA, weighted_bias=NA, 
                       weighted_warmth=NA, group=NA, nincidents=NA, 
                       nstudents=NA, rate=NA)
for (k in files){
  #print(i)
  load(paste(pth,k,sep=''))
  df <- as.matrix(m)
  m$data %>% 
    select(county_id, COMBOKEY) %>% 
    distinct() %>% 
    group_by(county_id) %>% 
    summarise(nschools=n()) -> n_schools
  m$data %>%
    group_by(county_id, group) %>%
    summarise(nincidents=sum(number), nstudents=sum(total_number)) %>%
    mutate(rate=nincidents/nstudents) -> rate
  n_schools %>%
    left_join(m$data[, c('county_id', 'weighted_bias', 'weighted_warmth')]) %>%
    distinct() %>%
    left_join(rate) %>%
    rbind(raw_rate) %>%
    filter(!is.na(county_id)) -> raw_rate
  posterior_combo[,,j] <- t(df[,c(1:14)])
  j <- j+1
}
p_cons <- parallelMCMCcombine::consensusMCcov(posterior_combo, shuff = T)

for (p in 1:14){
  m$stanfit@sim$samples[[1]][[p]] <- p_cons[p,1:1000]
}
for (p in 1:14){
  m$stanfit@sim$samples[[2]][[p]] <- p_cons[p,1001:2000]
}
for (p in 1:14){
  m$stanfit@sim$samples[[3]][[p]] <- p_cons[p,2001:3000]
}
for (p in 1:14){
  m$stanfit@sim$samples[[4]][[p]] <- p_cons[p,3001:4000]
}

newdat <- expand.grid(group = rownames(table(m$data$group)),
                      total_pop=0,
                      unemp_rate=0,
                      med_income=0,
                      poverty_rate=0,
                      col_grads=0,
                      white_prop=0,
                      black_prop=0,
                      b.w.ratio=0,
                      weighted_bias = seq(-2.5,2.5,.25),
                      weighted_warmth = 0,
                      number=0,
                      total_number=1)
y_hat <- rstanarm::posterior_linpred(m, newdata = newdat, re.form=~0, transform=T)

cbind(newdat, t(y_hat)) %>% 
  mutate(index=row_number()) %>%
  gather(sample, value, `1`:`4000`) -> posterior_distribution


posterior_distribution %>%
  select(group, weighted_bias, sample, value, index) %>%
  group_by(group, weighted_bias) %>%
  summarise(est = mean(value),
            lower = quantile(value, .025),
            upper = quantile(value, .975)) %>%
  ungroup() %>%
  mutate(bias = 'Implicit') -> plot.dat

newdat <- expand.grid(group = rownames(table(m$data$group)),
                      total_pop=0,
                      unemp_rate=0,
                      med_income=0,
                      poverty_rate=0,
                      col_grads=0,
                      white_prop=0,
                      black_prop=0,
                      b.w.ratio=0,
                      weighted_bias = 0,
                      weighted_warmth = seq(-2.5,2.5,.25),
                      number=0,
                      total_number=1)
y_hat <- rstanarm::posterior_linpred(m, newdata = newdat, re.form=~0, transform=T)

cbind(newdat, t(y_hat)) %>% 
  mutate(index=row_number()) %>%
  gather(sample, value, `1`:`4000`) -> posterior_distribution


posterior_distribution %>%
  select(group, weighted_warmth, sample, value, index) %>%
  mutate(weighted_bias = weighted_warmth) %>%
  group_by(group, weighted_bias) %>%
  summarise(est = mean(value),
            lower = quantile(value, .025),
            upper = quantile(value, .975)) %>%
  ungroup() %>%
  mutate(bias = 'Explicit') %>%
  rbind(plot.dat) -> plot.dat


ggplot(plot.dat, aes(x=weighted_bias, y=est, group=group, linetype=group)) +
  geom_line(aes(color=group)) +
  geom_ribbon(aes(ymin=lower, ymax=upper), alpha=.15) +
  theme_classic() +
  ylab('Probability of \n out-of-school suspension') +
  xlab('Standardized Bias') + 
  facet_wrap(~bias, ncol=2) +
  xlim(-3.5, 3.5) +
  theme(legend.title = element_blank(),
        axis.title.x = element_blank()) -> p1

posterior_distribution %>%
  select(group, weighted_warmth, sample, value) %>%
  spread(group, value) %>%
  mutate(ratio = black/white) %>%
  mutate(weighted_bias = weighted_warmth) %>%
  group_by(weighted_bias) %>%
  summarise(est = mean(ratio),
            lower = quantile(ratio, .025),
            upper = quantile(ratio, .975)) %>%
  ungroup() %>%
  mutate(bias = 'Explicit') -> plot.dat

newdat <- expand.grid(group = rownames(table(m$data$group)),
                      total_pop=0,
                      unemp_rate=0,
                      med_income=0,
                      poverty_rate=0,
                      col_grads=0,
                      white_prop=0,
                      black_prop=0,
                      b.w.ratio=0,
                      weighted_bias = seq(-2.5,2.5,.25),
                      weighted_warmth = 0,
                      number=0,
                      total_number=1)
y_hat <- rstanarm::posterior_linpred(m, newdata = newdat, re.form=~0, transform=T)

cbind(newdat, t(y_hat)) %>% 
  mutate(index=row_number()) %>%
  gather(sample, value, `1`:`4000`) -> posterior_distribution

posterior_distribution %>%
  select(group, weighted_bias, sample, value) %>%
  spread(group, value) %>%
  mutate(ratio = black/white) %>%
  group_by(weighted_bias) %>%
  summarise(est = mean(ratio),
            lower = quantile(ratio, .025),
            upper = quantile(ratio, .975)) %>%
  ungroup() %>%
  mutate(bias = 'Implicit') %>%
  rbind(plot.dat) -> plot.dat

raw_rate %>%
  mutate(Implicit = weighted_bias,
         Explicit = weighted_warmth) %>%
  select(-weighted_bias, -weighted_warmth) %>%
  gather(bias, value, Implicit:Explicit) %>%
  select(county_id, nschools, bias, group, rate, value) %>%
  spread(group, rate) %>%
  mutate(odds_r = black/white) -> raw_or
  

ggplot(plot.dat, aes(x=weighted_bias, y=est)) +
  geom_point(data=raw_or, aes(x=value, y=odds_r, size=nschools), alpha=.075) +
  geom_line() +
  geom_ribbon(aes(ymin=lower, ymax=upper), alpha=.25) +
  theme_classic() +
  #scale_color_manual(values=c('grey', 'darkorange'), guide=F) + 
  scale_alpha_manual(values=c(.2, 1), guide=F) +
  ylim(0,9) +
  xlim(-3.5, 3.5) + 
  xlab('Standardized Bias') +
  ylab('Relative \n Risk Ratio') +
  geom_hline(yintercept=1) +
  facet_wrap(~bias) -> p2

p1$data %>% filter(weighted_bias %in% c(0, 1)) -> rates
p2$data %>% filter(weighted_bias %in% c(0, 1)) -> risks

grid.arrange(p1, p2)
```

Figure \@ref(fig:detail-fig-susp) shows similar patterns, but for out-of-school suspensions. In a county at the mean of the distribution of bias, approximately `r round(rates$est*100, 1)[1]`% of black students are expected to be suspended [`r round(rates$lower*100, 1)[1]`, `r round(rates$upper*100, 1)[1]`]. The corresponding rate for white students is just over half that for black students, with about `r round(rates$est*100, 1)[3]`% expected to be suspended [`r round(rates$lower*100, 1)[3]`, `r round(rates$upper*100, 1)[3]`]. Moving to a county one standard deviation above the mean of explicit bias has the effect of slightly decreasing the estimated percentage of black students expected to be suspended to `r round(rates$est*100, 1)[2]`% [`r round(rates$lower*100, 1)[2]`, `r round(rates$upper*100, 1)[2]`], while the percentage of white students expected to be suspended would decrease at a faster rate to `r round(rates$est*100, 1)[4]`% [`r round(rates$lower*100, 1)[4]`, `r round(rates$upper*100, 1)[4]`]. The same movement for implicit bias would dramatically increase the expected suspensions for black students (`r round(rates$est*100, 1)[6]`% [`r round(rates$lower*100, 1)[6]`, `r round(rates$upper*100, 1)[6]`), and increase the expected suspensions for white students a much smaller amount to (`r round(rates$est*100, 1)[8]`% [`r round(rates$lower*100, 1)[8]`, `r round(rates$upper*100, 1)[8]`). In real terms, in a county at the mean of the distributions of bias, for every white student expelled, we should expect `r round(risks$est[1], 2)` [`r round(risks$lower[1], 2)`, `r round(risks$est[1], 2)`] black students to be expelled. If we move to a county one standard deviation above the mean of explicit bias, the ratio of black to white students expelled increases to `r round(risks$est[4], 2)` [`r round(risks$lower[4], 2)`, `r round(risks$est[4], 2)`], while the same movement for implicit bias slightly decreases the ratio to `r round(risks$est[2], 2)` [`r round(risks$lower[2], 2)`, `r round(risks$est[2], 2)`].`

# Discussion


\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\newpage
# Appendix
## Preregistered analysis
```{r summary_counts}

###############
schools_dat %>%
  select(LEA_STATE:LEAID, CCD_LATCOD, CCD_LONCOD, SCH_PSENR_HI_M:TOT_PSENR_F) %>%
  gather(group, total_number, SCH_PSENR_HI_M:TOT_PSENR_F) %>%
  separate(group, into=c('group', 'gender'), -2) %>%
  separate(group, into=c('prefix', 'group'), -4) %>%
  mutate(group=fct_recode(group, am_indian='AM_', asian='AS_', black='BL_',
                          hispanic='HI_', pac_isl='HP_', total='NR_', 
                          biracial='TR_', white='WH_')) %>%
  filter(total_number>=0) %>%
  group_by(COMBOKEY, group) %>%
  mutate(total_number = sum(total_number)) %>%
  ungroup() %>%
  select(-prefix, -gender) %>%
  distinct() -> ps_enrollment

schools_dat %>% 
  select(LEA_STATE:LEAID, CCD_LATCOD, CCD_LONCOD, 
         SCH_GRADE_PS, SCH_PSDISC_SINGOOS_HI_M:TOT_PSDISC_SINGOOS_F) %>% 
  filter(SCH_GRADE_PS=='YES') %>%
  gather(group, number, SCH_PSDISC_SINGOOS_HI_M:TOT_PSDISC_SINGOOS_F) %>%
  separate(group, into=c('group', 'gender'), -2) %>% 
  separate(group, into=c('prefix', 'group'), -4) %>%
  mutate(group=fct_recode(group, am_indian='AM_', asian='AS_', black='BL_',
                          hispanic='HI_', pac_isl='HP_', total='OS_', 
                          biracial='TR_', white='WH_')) %>%
  select(-prefix) -> ps_susp

schools_dat %>% 
  select(LEA_STATE:LEAID, CCD_LATCOD, CCD_LONCOD,
         SCH_GRADE_PS, SCH_PSDISC_MULTOOS_HI_M:TOT_PSDISC_MULTOOS_F) %>% 
  filter(SCH_GRADE_PS=='YES') %>%
  gather(group, number_2, SCH_PSDISC_MULTOOS_HI_M:TOT_PSDISC_MULTOOS_F) %>%
  separate(group, into=c('group', 'gender'), -2) %>%
  separate(group, into=c('prefix', 'group'), -4) %>%
  mutate(group=fct_recode(group, am_indian='AM_', asian='AS_', black='BL_',
                          hispanic='HI_', pac_isl='HP_', total='OS_', 
                          biracial='TR_', white='WH_')) %>%
  select(COMBOKEY, group, gender, number_2) %>%
  right_join(ps_susp) %>%
  filter(number>=0 & number_2 >= 0) %>%
  mutate(number = number+number_2) -> ps_susp

schools_dat %>% 
  select(LEA_STATE:LEAID, CCD_LATCOD, CCD_LONCOD, 
         SCH_PSDISC_EXP_HI_M:TOT_PSDISC_EXP_F) %>% 
  gather(group, number, SCH_PSDISC_EXP_HI_M:TOT_PSDISC_EXP_F) %>%
  separate(group, into=c('group', 'gender'), -2) %>% 
  separate(group, into=c('prefix', 'group'), -4) %>%
  mutate(group=fct_recode(group, am_indian='AM_', asian='AS_', black='BL_',
                          hispanic='HI_', pac_isl='HP_', total='XP_', 
                          biracial='TR_', white='WH_')) %>%
  filter(number>=0) %>%
  select(-prefix) -> ps_exp

ps_susp %>% group_by(group) %>% summarise(n_students=sum(number)) -> susp_summ
ps_exp %>% group_by(group) %>% summarise(n_students=sum(number)) -> exp_summ
ps_enrollment %>% group_by(group) %>% summarise(n_students=sum(total_number)) -> enr_summ



#s, 

```
In our preanalysis plan, we specified our analyses to focus on 13 actions - corporal punishment, in-school suspension, out-of-school suspension, expulsion with educational services, expulsion without educational services, expulsion under zero-tolerance policies, referral to law enforcement, school-related arrests, mechanical restraint, physical restraint, seclusion, preschool suspension, and preschool expulsion.  However, upon further study, we discovered reasons we thought justified excluding a number of these outcomes. In particular, seclusion, physical restraint, and mechanical restraint are not disciplinary actions, but are rather used as means to restrain students who are at risk of harming themselves or others. Additionally, the number of preschool students who are expelled or suspended is vanishingly small (`r exp_summ$n_students[8]` total expulsions and `r susp_summ$n_students[6]` total suspensions out of over 1.4 million enrolled preschool students), making reliably estimating any association across counties exceedingly unlikely. We additionally discovered that counts of one expulsion category (expulsion under zero-tolerance policies) overlapped with counts in other categories, and so excluded this category. Finally, to remain consistent with previous studies, we opted to combine the remaining two expulsion categories to yield one overall count of the number of students expelled. 

We also preregistered our explicit bias as a simple feeling thermometer towards balcks (i.e. *how warm or cold do you feel towards Blacks? 0=very cold, 10=very warm*). However, past research [@leitner2016blacks; @hehman2017disproportionate] has used the difference in reported warmth towards whites and blacks, and so in the main text, we report models using this metric of explicit bias. Additionally, we preregistered analyses with poststratified estimates (as presented in the main text) along with raw, county-based means. We also had not known about the issues with juvenile justice facilities, or with the school districts with reporting errors, and so excluded these schools from analyses in the main text. Finally, we also registered an exploratory analysis using the responses of people who visited Project Implicit and identified themselves as teachers. Ultimately, we believe that there were too few individuals in the data to obtain reliable county-level estimates for this subgroup, and so this analysis is also limited to the appendix. Here, we present the results of the preregistered analyses exactly. Table \@ref(tab:all-results) presents the estimates (operationalized as the mean of the posterior), 95% uncertainty intervals, and the proportion of the posterior that is consistent with a negative effect for all of the outcomes for each of these models (*Model A*: raw county means estimates; *Model B*: post-stratified estimates using simple warmth score, *Model C*: teacher analyses).

```{r all-results, results='asis'}
base_path <- '/Users/travis/Documents/gits/educational_disparities/cluster/output/metrics_raw/'
plot.dat <- data.frame(group = NA, weighted_bias = NA, est = NA, lower = NA, upper=NA, metric = NA)
plot.dat2 <- data.frame(weighted_bias = NA, est = NA, lower=NA, upper=NA, metric=NA)
plot.dat3 <- data.frame(est=NA, lower=NA, upper=NA, p_neg=NA, metric=NA)

metrics <- list.files(base_path)
#metrics <- c('expulsion_combined', 'inschool_susp', 'oos_susp')
for (i in metrics){
  pth <- paste(base_path, i, '/', sep='')
  
  files <- list.files(pth)
  j <- 1
  posterior_combo <- array(0, dim=c(14,4000,length(files)))
  raw_rate <- data.frame(county_id=NA, nschools=NA, weighted_bias=NA, group=NA, nincidents=NA, nstudents=NA, rate=NA)
  for (k in files){
    #print(i)
    load(paste(pth,k,sep=''))
    df <- as.matrix(m)
    m$data %>% 
      select(county_id, COMBOKEY) %>% 
      distinct() %>% 
      group_by(county_id) %>% 
      summarise(nschools=n()) -> n_schools
    m$data %>%
      group_by(county_id, group) %>%
      summarise(nincidents=sum(number), nstudents=sum(total_number)) %>%
      mutate(rate=nincidents/nstudents) -> rate
    n_schools %>%
      left_join(m$data[, c('county_id', 'weighted_bias')]) %>%
      distinct() %>%
      left_join(rate) %>%
      rbind(raw_rate) %>%
      filter(!is.na(county_id)) -> raw_rate
    posterior_combo[,,j] <- t(df[,c(1:14)])
    j <- j+1
  }
  p_cons <- parallelMCMCcombine::consensusMCcov(posterior_combo, shuff = T)
  
  for (p in 1:14){
    m$stanfit@sim$samples[[1]][[p]] <- p_cons[p,1:1000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[2]][[p]] <- p_cons[p,1001:2000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[3]][[p]] <- p_cons[p,2001:3000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[4]][[p]] <- p_cons[p,3001:4000]
  }
  
  data.frame(est=mean(p_cons[13,]),
             lower=quantile(p_cons[13,], .025),
             upper=quantile(p_cons[13,], .975),
             p_neg = prop.table(table(p_cons[13,]<0))[2],
             metric=i) %>%
    rbind(plot.dat3) %>%
    filter(!is.na(est)) %>%
    mutate(metric=reorder(metric, est)) -> plot.dat3
}

plot.dat3$metric <- fct_recode(plot.dat3$metric, 
                               'Out-of-School Suspension' = 'oos_susp',
                               'In-School Suspension' = 'inschool_susp',
                               'School-Related Arrest' = 'in_school_arrest',
                               'Law Enf. Referral' = 'law_enforcement',
                               'Corporal Punishment' = 'corporal',
                               'Expulsion Under Zero-Tolerance' = 'expulsion_0_tolerance',
                               'Expulsion with Educational Services' = 'expulsion_w_ed',
                               'Expulsion without Educational Services' = 'expulsion_wo_ed',
                               'Mechanical Restraint' = 'mechanical_restraint',
                               'Physical Restraint' = 'physical_restraint',
                               'Preschool Expulsion' = 'preschool_expulsion',
                               'Preschool Suspension' = 'preschool_susp',
                               'Seclusion' = 'seclusion')
plot.dat3$model <- 'A'
plot.dat3_all <-plot.dat3
plot.dat3_all$bias <- 'Implicit'

#weighted warmth w/exclusions & explicit difference
plot.dat <- data.frame(group = NA, weighted_warmth = NA, est = NA, lower = NA, upper=NA, metric = NA)
plot.dat2 <- data.frame(weighted_warmth = NA, est = NA, lower=NA, upper=NA, metric=NA)
plot.dat3 <- data.frame(est=NA, lower=NA, upper=NA, p_neg = NA, metric=NA)

for(i in metrics){
  pth <- paste(base_path, i, '/', sep='')
  
  files <- list.files(pth)
  j <- 1
  posterior_combo <- array(0, dim=c(14,4000,length(files)))
  raw_rate_warmth <- data.frame(county_id=NA, nschools=NA, weighted_warmth=NA, group=NA, nincidents=NA, nstudents=NA, rate=NA)
  for (k in files){
    #print(i)
    load(paste(pth,k,sep=''))
    df <- as.matrix(m)
    m$data %>% 
      select(county_id, COMBOKEY) %>% 
      distinct() %>% 
      group_by(county_id) %>% 
      summarise(nschools=n()) -> n_schools
    m$data %>%
      group_by(county_id, group) %>%
      summarise(nincidents=sum(number), nstudents=sum(total_number)) %>%
      mutate(rate=nincidents/nstudents) -> rate
    n_schools %>%
      left_join(m$data[, c('county_id', 'weighted_warmth')]) %>%
      distinct() %>%
      left_join(rate) %>%
      rbind(raw_rate_warmth) %>%
      filter(!is.na(county_id)) -> raw_rate_warmth
    posterior_combo[,,j] <- t(df[,c(1:14)])
    j <- j+1
  }
  p_cons <- parallelMCMCcombine::consensusMCcov(posterior_combo, shuff = T)
  
  for (p in 1:14){
    m$stanfit@sim$samples[[1]][[p]] <- p_cons[p,1:1000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[2]][[p]] <- p_cons[p,1001:2000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[3]][[p]] <- p_cons[p,2001:3000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[4]][[p]] <- p_cons[p,3001:4000]
  }
  
  data.frame(est=mean(p_cons[14,]),
             lower=quantile(p_cons[14,], .025),
             upper=quantile(p_cons[14,], .975),
             p_neg = prop.table(table(p_cons[14,]<0))[2],
             metric=i) %>%
    rbind(plot.dat3) %>%
    filter(!is.na(est)) %>%
    mutate(metric=reorder(metric, est)) -> plot.dat3
}

plot.dat3$bias <- 'Explicit'
plot.dat3$metric <- fct_recode(plot.dat3$metric, 
                               'Out-of-School Suspension' = 'oos_susp',
                               'In-School Suspension' = 'inschool_susp',
                               'School-Related Arrest' = 'in_school_arrest',
                               'Law Enf. Referral' = 'law_enforcement',
                               'Corporal Punishment' = 'corporal',
                               'Expulsion Under Zero-Tolerance' = 'expulsion_0_tolerance',
                               'Expulsion with Educational Services' = 'expulsion_w_ed',
                               'Expulsion without Educational Services' = 'expulsion_wo_ed',
                               'Mechanical Restraint' = 'mechanical_restraint',
                               'Physical Restraint' = 'physical_restraint',
                               'Preschool Expulsion' = 'preschool_expulsion',
                               'Preschool Suspension' = 'preschool_susp',
                               'Seclusion' = 'seclusion')
plot.dat3$model <- 'A'
table_dat <- rbind(plot.dat3_all, plot.dat3)

base_path <- '/Users/travis/Documents/gits/educational_disparities/cluster/output/metrics_weighted/older_run/'
plot.dat <- data.frame(group = NA, weighted_bias = NA, est = NA, lower = NA, upper=NA, metric = NA)
plot.dat2 <- data.frame(weighted_bias = NA, est = NA, lower=NA, upper=NA, metric=NA)
plot.dat3 <- data.frame(est=NA, lower=NA, upper=NA, p_neg=NA, metric=NA)

# weighted bias w/exclusions & explicit difference
metrics <- list.files(base_path)

for (i in metrics){
  pth <- paste(base_path, i, '/', sep='')
  
  files <- list.files(pth)
  j <- 1
  posterior_combo <- array(0, dim=c(14,4000,length(files)))
  raw_rate <- data.frame(county_id=NA, nschools=NA, weighted_bias=NA, group=NA, nincidents=NA, nstudents=NA, rate=NA)
  for (k in files){
    #print(i)
    load(paste(pth,k,sep=''))
    df <- as.matrix(m)
    m$data %>% 
      select(county_id, COMBOKEY) %>% 
      distinct() %>% 
      group_by(county_id) %>% 
      summarise(nschools=n()) -> n_schools
    m$data %>%
      group_by(county_id, group) %>%
      summarise(nincidents=sum(number), nstudents=sum(total_number)) %>%
      mutate(rate=nincidents/nstudents) -> rate
    n_schools %>%
      left_join(m$data[, c('county_id', 'weighted_bias')]) %>%
      distinct() %>%
      left_join(rate) %>%
      rbind(raw_rate) %>%
      filter(!is.na(county_id)) -> raw_rate
    posterior_combo[,,j] <- t(df[,c(1:14)])
    j <- j+1
  }
  p_cons <- parallelMCMCcombine::consensusMCcov(posterior_combo, shuff = T)
  
  for (p in 1:14){
    m$stanfit@sim$samples[[1]][[p]] <- p_cons[p,1:1000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[2]][[p]] <- p_cons[p,1001:2000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[3]][[p]] <- p_cons[p,2001:3000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[4]][[p]] <- p_cons[p,3001:4000]
  }
  
  data.frame(est=mean(p_cons[13,]),
             lower=quantile(p_cons[13,], .025),
             upper=quantile(p_cons[13,], .975),
             p_neg = prop.table(table(p_cons[13,]<0))[2],
             metric=i) %>%
    rbind(plot.dat3) %>%
    filter(!is.na(est)) %>%
    mutate(metric=reorder(metric, est)) -> plot.dat3
}

plot.dat3$metric <- fct_recode(plot.dat3$metric, 
                               'Out-of-School Suspension' = 'oos_susp',
                               'In-School Suspension' = 'inschool_susp',
                               'School-Related Arrest' = 'in_school_arrest',
                               'Law Enf. Referral' = 'law_enforcement',
                               'Corporal Punishment' = 'corporal',
                               'Expulsion Under Zero-Tolerance' = 'expulsion_0_tolerance',
                               'Expulsion with Educational Services' = 'expulsion_w_ed',
                               'Expulsion without Educational Services' = 'expulsion_wo_ed',
                               'Mechanical Restraint' = 'mechanical_restraint',
                               'Physical Restraint' = 'physical_restraint',
                               'Preschool Expulsion' = 'preschool_expulsion',
                               'Preschool Suspension' = 'preschool_susp',
                               'Seclusion' = 'seclusion')
plot.dat3$model <- 'B'
plot.dat3_all <-plot.dat3
plot.dat3_all$bias <- 'Implicit'

#weighted warmth w/exclusions & explicit difference
plot.dat <- data.frame(group = NA, weighted_warmth = NA, est = NA, lower = NA, upper=NA, metric = NA)
plot.dat2 <- data.frame(weighted_warmth = NA, est = NA, lower=NA, upper=NA, metric=NA)
plot.dat3 <- data.frame(est=NA, lower=NA, upper=NA, p_neg = NA, metric=NA)

for(i in metrics){
  pth <- paste(base_path, i, '/', sep='')
  
  files <- list.files(pth)
  j <- 1
  posterior_combo <- array(0, dim=c(14,4000,length(files)))
  raw_rate_warmth <- data.frame(county_id=NA, nschools=NA, weighted_warmth=NA, group=NA, nincidents=NA, nstudents=NA, rate=NA)
  for (k in files){
    #print(i)
    load(paste(pth,k,sep=''))
    df <- as.matrix(m)
    m$data %>% 
      select(county_id, COMBOKEY) %>% 
      distinct() %>% 
      group_by(county_id) %>% 
      summarise(nschools=n()) -> n_schools
    m$data %>%
      group_by(county_id, group) %>%
      summarise(nincidents=sum(number), nstudents=sum(total_number)) %>%
      mutate(rate=nincidents/nstudents) -> rate
    n_schools %>%
      left_join(m$data[, c('county_id', 'weighted_warmth')]) %>%
      distinct() %>%
      left_join(rate) %>%
      rbind(raw_rate_warmth) %>%
      filter(!is.na(county_id)) -> raw_rate_warmth
    posterior_combo[,,j] <- t(df[,c(1:14)])
    j <- j+1
  }
  p_cons <- parallelMCMCcombine::consensusMCcov(posterior_combo, shuff = T)
  
  for (p in 1:14){
    m$stanfit@sim$samples[[1]][[p]] <- p_cons[p,1:1000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[2]][[p]] <- p_cons[p,1001:2000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[3]][[p]] <- p_cons[p,2001:3000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[4]][[p]] <- p_cons[p,3001:4000]
  }
  
  data.frame(est=mean(p_cons[14,]),
             lower=quantile(p_cons[14,], .025),
             upper=quantile(p_cons[14,], .975),
             p_neg = prop.table(table(p_cons[14,]<0))[2],
             metric=i) %>%
    rbind(plot.dat3) %>%
    filter(!is.na(est)) %>%
    mutate(metric=reorder(metric, est)) -> plot.dat3
}

plot.dat3$bias <- 'Explicit'
plot.dat3$metric <- fct_recode(plot.dat3$metric, 
                               'Out-of-School Suspension' = 'oos_susp',
                               'In-School Suspension' = 'inschool_susp',
                               'School-Related Arrest' = 'in_school_arrest',
                               'Law Enf. Referral' = 'law_enforcement',
                               'Corporal Punishment' = 'corporal',
                               'Expulsion Under Zero-Tolerance' = 'expulsion_0_tolerance',
                               'Expulsion with Educational Services' = 'expulsion_w_ed',
                               'Expulsion without Educational Services' = 'expulsion_wo_ed',
                               'Mechanical Restraint' = 'mechanical_restraint',
                               'Physical Restraint' = 'physical_restraint',
                               'Preschool Expulsion' = 'preschool_expulsion',
                               'Preschool Suspension' = 'preschool_susp',
                               'Seclusion' = 'seclusion')
plot.dat3$model <- 'B'
plot.dat3 %>%
  rbind(plot.dat3_all) %>%
  rbind(table_dat) -> table_dat

base_path <- '/Users/travis/Documents/gits/educational_disparities/cluster/output/teacher_metrics/'
plot.dat <- data.frame(group = NA, county_bias = NA, est = NA, lower = NA, upper=NA, metric = NA)
plot.dat2 <- data.frame(county_bias = NA, est = NA, lower=NA, upper=NA, metric=NA)
plot.dat3 <- data.frame(est=NA, lower=NA, upper=NA, p_neg=NA, metric=NA)

# weighted bias w/exclusions & explicit difference
metrics <- list.files(base_path)

for (i in metrics){
  pth <- paste(base_path, i, '/', sep='')
  
  files <- list.files(pth)
  j <- 1
  posterior_combo <- array(0, dim=c(14,4000,length(files)))
  raw_rate <- data.frame(county_id=NA, nschools=NA, county_bias=NA, group=NA, nincidents=NA, nstudents=NA, rate=NA)
  for (k in files){
    #print(i)
    load(paste(pth,k,sep=''))
    df <- as.matrix(m)
    m$data %>% 
      select(county_id, COMBOKEY) %>% 
      distinct() %>% 
      group_by(county_id) %>% 
      summarise(nschools=n()) -> n_schools
    m$data %>%
      group_by(county_id, group) %>%
      summarise(nincidents=sum(number), nstudents=sum(total_number)) %>%
      mutate(rate=nincidents/nstudents) -> rate
    n_schools %>%
      left_join(m$data[, c('county_id', 'county_bias')]) %>%
      distinct() %>%
      left_join(rate) %>%
      rbind(raw_rate) %>%
      filter(!is.na(county_id)) -> raw_rate
    posterior_combo[,,j] <- t(df[,c(1:14)])
    j <- j+1
  }
  p_cons <- parallelMCMCcombine::consensusMCcov(posterior_combo, shuff = T)
  
  for (p in 1:14){
    m$stanfit@sim$samples[[1]][[p]] <- p_cons[p,1:1000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[2]][[p]] <- p_cons[p,1001:2000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[3]][[p]] <- p_cons[p,2001:3000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[4]][[p]] <- p_cons[p,3001:4000]
  }
  
  data.frame(est=mean(p_cons[13,]),
             lower=quantile(p_cons[13,], .025),
             upper=quantile(p_cons[13,], .975),
             p_neg = prop.table(table(p_cons[13,]<0))[2],
             metric=i) %>%
    rbind(plot.dat3) %>%
    filter(!is.na(est)) %>%
    mutate(metric=reorder(metric, est)) -> plot.dat3
}

plot.dat3$metric <- fct_recode(plot.dat3$metric, 
                               'Out-of-School Suspension' = 'oos_susp',
                               'In-School Suspension' = 'inschool_susp',
                               'School-Related Arrest' = 'in_school_arrest',
                               'Law Enf. Referral' = 'law_enforcement',
                               'Corporal Punishment' = 'corporal',
                               'Expulsion Under Zero-Tolerance' = 'expulsion_0_tolerance',
                               'Expulsion with Educational Services' = 'expulsion_w_ed',
                               'Expulsion without Educational Services' = 'expulsion_wo_ed',
                               'Mechanical Restraint' = 'mechanical_restraint',
                               'Physical Restraint' = 'physical_restraint',
                               'Preschool Expulsion' = 'preschool_expulsion',
                               'Preschool Suspension' = 'preschool_susp',
                               'Seclusion' = 'seclusion')
plot.dat3$model <- 'C'
plot.dat3_all <-plot.dat3
plot.dat3_all$bias <- 'Implicit'

plot.dat <- data.frame(group = NA, county_warmth = NA, est = NA, lower = NA, upper=NA, metric = NA)
plot.dat2 <- data.frame(county_warmth = NA, est = NA, lower=NA, upper=NA, metric=NA)
plot.dat3 <- data.frame(est=NA, lower=NA, upper=NA, p_neg = NA, metric=NA)

for(i in metrics){
  pth <- paste(base_path, i, '/', sep='')
  
  files <- list.files(pth)
  j <- 1
  posterior_combo <- array(0, dim=c(14,4000,length(files)))
  raw_rate_warmth <- data.frame(county_id=NA, nschools=NA, county_warmth=NA, group=NA, nincidents=NA, nstudents=NA, rate=NA)
  for (k in files){
    #print(i)
    load(paste(pth,k,sep=''))
    df <- as.matrix(m)
    m$data %>% 
      select(county_id, COMBOKEY) %>% 
      distinct() %>% 
      group_by(county_id) %>% 
      summarise(nschools=n()) -> n_schools
    m$data %>%
      group_by(county_id, group) %>%
      summarise(nincidents=sum(number), nstudents=sum(total_number)) %>%
      mutate(rate=nincidents/nstudents) -> rate
    n_schools %>%
      left_join(m$data[, c('county_id', 'county_warmth')]) %>%
      distinct() %>%
      left_join(rate) %>%
      rbind(raw_rate_warmth) %>%
      filter(!is.na(county_id)) -> raw_rate_warmth
    posterior_combo[,,j] <- t(df[,c(1:14)])
    j <- j+1
  }
  p_cons <- parallelMCMCcombine::consensusMCcov(posterior_combo, shuff = T)
  
  for (p in 1:14){
    m$stanfit@sim$samples[[1]][[p]] <- p_cons[p,1:1000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[2]][[p]] <- p_cons[p,1001:2000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[3]][[p]] <- p_cons[p,2001:3000]
  }
  for (p in 1:14){
    m$stanfit@sim$samples[[4]][[p]] <- p_cons[p,3001:4000]
  }
  
  data.frame(est=mean(p_cons[14,]),
             lower=quantile(p_cons[14,], .025),
             upper=quantile(p_cons[14,], .975),
             p_neg = prop.table(table(p_cons[14,]<0))[2],
             metric=i) %>%
    rbind(plot.dat3) %>%
    filter(!is.na(est)) %>%
    mutate(metric=reorder(metric, est)) -> plot.dat3
}

plot.dat3$bias <- 'Explicit'
plot.dat3$metric <- fct_recode(plot.dat3$metric, 
                               'Out-of-School Suspension' = 'oos_susp',
                               'In-School Suspension' = 'inschool_susp',
                               'School-Related Arrest' = 'in_school_arrest',
                               'Law Enf. Referral' = 'law_enforcement',
                               'Corporal Punishment' = 'corporal',
                               'Expulsion Under Zero-Tolerance' = 'expulsion_0_tolerance',
                               'Expulsion with Educational Services' = 'expulsion_w_ed',
                               'Expulsion without Educational Services' = 'expulsion_wo_ed',
                               'Mechanical Restraint' = 'mechanical_restraint',
                               'Physical Restraint' = 'physical_restraint',
                               'Preschool Expulsion' = 'preschool_expulsion',
                               'Preschool Suspension' = 'preschool_susp',
                               'Seclusion' = 'seclusion')
plot.dat3$model <- 'C'
plot.dat3 %>%
  rbind(plot.dat3_all) %>%
  rbind(table_dat) -> table_dat
# ggplot(table_dat, aes(x=metric, y=est, group=model, color=model, shape=model)) +
#   geom_point(position=position_dodge(width=.5), size=2) +
#   geom_errorbar(aes(ymin=lower, ymax=upper), 
#                 width=.5, position=position_dodge(width=.5)) +
#   theme_classic() +
#   coord_flip() +
#   geom_hline(yintercept=0) +
#   ylab('Black-White Difference in log-odds slope') +
#   theme(axis.title.y = element_blank(),
#         legend.title = element_blank(),
#         axis.title.x = element_text(size=14),
#         axis.text = element_text(size=12),
#         legend.text = element_text(size=12),
#         strip.text = element_text(size=12)) +
#   facet_wrap(~bias)
table_dat$p_neg[which(is.na(table_dat$p_neg))] <- 1
table_dat %>%
  mutate(UI = paste('[', round(lower, 2), ', ', round(upper, 2), ']', sep='')) %>%
  select(est, UI, p_neg, metric, bias, model) %>%
  mutate(val = paste(round(est, 2), ', ', UI, sep=''),
         model = paste('Model ', model, sep='')) %>%
  select(val, metric, bias, model) %>%
  spread(model, val) %>%
  arrange(bias, metric) -> tabdat

papaja::apa_table(tabdat, caption = 'Effect estimates (operationalized as the mean of the posterior distribution for the difference in log-odds slope between black and white students) and 95% uncertainty intervals for all of the outcomes for each model (*Model A*: raw county means estimates; *Model B*: post-stratified estimates using simple warmth score, *Model C*: teacher analyses)', small = T)
```

#County-level estimates

```{r raw-county-estimates, fig.cap='Difference in raw county means and post-stratifed estimates of implicit bias as a function of the number of observations in each county. The X axis is on the log scale.'}
individual_data %>%
  group_by(county_id) %>%
  summarise(n_obs=n()) %>%
  left_join(county_means) -> cm

cm %>%
  mutate(post_diff = as.numeric(bias) - as.numeric(weighted_bias)) %>%
  ggplot(aes(x=n_obs, y=post_diff)) + 
  geom_point() + 
  scale_x_log10(breaks=c(1, 10, 100, 1000, 10000)) +
  theme_classic() +
  ylab('Raw Bias - Weighted Bias difference') +
  xlab('Number of Observations')

```

Examining the models fit with simple county means, we find that the county-level estimates vary more than with the post-stratified estimates. This pattern is expected, as one desireable feature of post-stratification is that it regularizes extreme observations without a large amount of data to suppor them. This phenomena is illustrated in figure \@ref(fig:raw-county-estimates), which shows the distribution of differences between the raw county means and the post-stratified estimates of implicit bias as a function of the number of observations in each county. More specifically, while the mean of the county-level means does not meaningfully differ from the post-stratified estimates, the standard deviation is much larger ($M_{implicit}$ = `r round(mean(as.numeric(cm$bias), na.rm=T), 2)`, $SD_{implicit}$ = `r round(sd(as.numeric(cm$bias), na.rm=T), 2)`; $M_{explicit}$ = `r round(mean(as.numeric(cm$explicit), na.rm=T), 2)`, $SD_{explicit}$ = `r round(sd(as.numeric(cm$explicit), na.rm=T), 2)`)[^2]

[^2]: This explicit estimate is based on the simple warmth towards blacks question, and not the difference between warmth towards whites and warmth twoards blacks.

The county-level implicit bias estimates for the poststratified model are as reported in the main text. The estimates for explicit bias are slightly different, as they are not computed based on the difference in reporting warmth toward whites and warmth toward blacks. Specifically, the average amount of bias at the county-level is `r round(mean(as.numeric(cm$weighted_explicit)*-1, na.rm=T), 2)` (SD = `r round(sd(as.numeric(cm$weighted_explicit), na.rm=T), 2)`).

```{r teachers-summary}
df <- rbind(read_sav('/Users/travis/Documents/gits/Data/iat/Race IAT.public.2013.sav'),
            read_sav('/Users/travis/Documents/gits/Data/iat/Race IAT.public.2012.sav'),
            read_sav('/Users/travis/Documents/gits/Data/iat/Race IAT.public.2010.sav'))

educators <- c('25-2000', '25-3000')

df %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblack_0to10) &
           !is.na(age)) %>%
  select(CountyNo, STATE, D_biep.White_Good_all, 
         twhite_0to10, tblack_0to10, raceomb, age, occupation)  -> subdat

df2 %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblack_0to10) &
           !is.na(age)) %>%
  select(CountyNo, STATE, D_biep.White_Good_all, 
         twhite_0to10, tblack_0to10, raceomb, age, occupation) %>%
  rbind(subdat) -> subdat

df3 %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblack_0to10) &
           !is.na(age)) %>%
  select(CountyNo, STATE, D_biep.White_Good_all, 
         twhite_0to10, tblack_0to10, raceomb, age, occupation) %>%
  rbind(subdat) -> subdat

df4 %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblack_0to10) &
           !is.na(age)) %>%
  select(CountyNo, STATE, D_biep.White_Good_all, 
         twhite_0to10, tblack_0to10, raceomb, age, occupation) %>%
  rbind(subdat) -> subdat

df5 %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblack_0to10) &
           !is.na(age)) %>%
  select(CountyNo, STATE, D_biep.White_Good_all, 
         twhite_0to10, tblack_0to10, raceomb, age, occupation) %>%
  rbind(subdat) -> subdat

df6 %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblack_0to10) &
           !is.na(age)) %>%
  select(CountyNo, STATE, D_biep.White_Good_all, 
         twhite_0to10, tblack_0to10, raceomb, age, occupation) %>%
  rbind(subdat) -> subdat

df10 %>%
  filter(CountyNo!='' &
           !is.na(D_biep.White_Good_all) &
           !is.na(tblack_0to10) &
           !is.na(age)) %>%
  select(CountyNo, STATE, D_biep.White_Good_all, 
         twhite_0to10, tblack_0to10, raceomb, age, occupation) %>%
  rbind(subdat) -> subdat

subdat %>%
  filter(raceomb==6) %>%
  mutate(explicit_diff=twhite_0to10 - tblack_0to10,
         explicit = tblack_0to10*-1) %>%
  filter(STATE %ni% 
           c('AA', 'AE', 'AP', 'AS', 'FM', 'GU', 'MH', 'MP', 'PR', 'VI')) %>%
  filter(occupation %in% educators) %>%
  mutate(county_id = paste(STATE, CountyNo, sep='-')) -> individual_data_teachers

teacher_estimates <- read.csv('/Users/travis/Documents/gits/educational_disparities/output/county_teacher_means.csv')
```

A subset of years in the Project Implicit data also collected occupational information from respondents. As identified in our pre-analysis plan, we took advantage of the presence of primary and secondary educators in these data to test whether any associations between bias and race-based differences in the rates of disciplinary action were stronger among these respondents. Filtering for only white individuals who identified as primary, secondary, special education, and other teachers and instructors (occupation codes 25-2000 and 25-3000) reduced the dataset to `r dim(individual_data_teachers)[1]` respondents. In order to assure that our estimates were reasonably stable, we limited analysis to only counties that had at least 50 respondents. As such, our teacher analysis is limited to just `r dim(teacher_estimates)[1]` counties. Additionally, because we do not know of any state-level demographic estimates for teachers, we were unable to perform post-stratification for these data. Nonetheless, across these limited counties, the overall estimate of implicit and explicit bias are similar to those for the whole dataset ($M_{implicit}$ = `r round(mean(as.numeric(teacher_estimates$teacher_bias), na.rm=T), 2)`, $SD_{implicit}$ = `r round(sd(as.numeric(teacher_estimates$teacher_bias), na.rm=T), 2)`; $M_{explicit}$ = `r round(mean(as.numeric(teacher_estimates$teacher_explicit), na.rm=T), 2)`, $SD_{explicit}$ = `r round(sd(as.numeric(teacher_estimates$teacher_explicit), na.rm=T), 2)`)

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
